/**
 * LLM integration module for Vibe Scan.
 *
 * This module provides an interface to call Groq's OpenAI-compatible API
 * to analyze code snippets for "vibe-coded" / production-risk issues.
 *
 * IMPORTANT NOTES:
 * - This is experimental and should NOT block CI on failures.
 * - The LLM is advisory and can be noisy; results should be used as hints.
 * - Callers should treat `null` returns as "LLM unavailable" and fall back
 *   to static analysis only.
 */

import OpenAI from "openai";
import { config } from "./config";

// ============================================================================
// Types
// ============================================================================

/**
 * Categories of issues the LLM can identify.
 */
export type LlmIssueKind =
  | "MISSING_ERROR_HANDLING"
  | "HIDDEN_ASSUMPTIONS"
  | "SCALING_RISK"
  | "CONCURRENCY_RISK"
  | "TEMPORARY_HACK"
  | "POOR_OBSERVABILITY"
  | "OTHER";

/**
 * Severity levels:
 * 0 = no issue
 * 1 = low
 * 2 = medium
 * 3 = high
 */
export type LlmSeverity = 0 | 1 | 2 | 3;

/**
 * A single issue identified by the LLM.
 */
export interface LlmIssue {
  kind: LlmIssueKind;
  severity: LlmSeverity;
  title: string; // short label
  explanation: string; // brief human-readable explanation
  suggestedFix?: string; // optional fix guidance
}

/**
 * The overall result from LLM analysis.
 */
export interface LlmAnalysisResult {
  overallSeverity: LlmSeverity;
  issues: LlmIssue[];
}

// ============================================================================
// OpenAI Client Setup (configured for Groq)
// ============================================================================

/**
 * Create an OpenAI client configured to use Groq's API.
 * We lazily create this to avoid errors if GROQ_API_KEY is not set.
 */
function createOpenAIClient(): OpenAI | null {
  if (!config.GROQ_API_KEY) {
    return null;
  }

  return new OpenAI({
    apiKey: config.GROQ_API_KEY,
    baseURL: process.env.GROQ_BASE_URL || "https://api.groq.com/openai/v1",
  });
}

// ============================================================================
// Prompt Building
// ============================================================================

/**
 * Build the prompt for vibe-coded analysis.
 */
function buildVibePrompt(params: {
  file: string;
  language?: string;
  snippet: string;
  diffContext?: string;
}): string {
  const { file, language, snippet, diffContext } = params;

  const languageHint = language ? ` (${language})` : "";
  const diffSection = diffContext
    ? `\n\nDiff context (surrounding changes):\n\`\`\`\n${diffContext}\n\`\`\``
    : "";

  return `You are a senior production engineer reviewing code for production readiness.

Your task is to analyze the following code snippet for "vibe-coded" issues. "Vibe-coded" refers to code that:
- Was written quickly as a prototype or generated by AI without careful review
- Contains hidden assumptions that may break under different conditions
- Lacks proper error handling for production scenarios
- May be fragile under load or concurrent access
- Has temporary hacks or TODOs that should be addressed
- Lacks observability (logging, metrics, tracing) for debugging in production

Analyze this code from file: ${file}${languageHint}

Code snippet:
\`\`\`
${snippet}
\`\`\`${diffSection}

Respond ONLY with a JSON object matching this exact structure (no additional text):

{
  "overallSeverity": 0 | 1 | 2 | 3,
  "issues": [
    {
      "kind": "MISSING_ERROR_HANDLING" | "HIDDEN_ASSUMPTIONS" | "SCALING_RISK" | "CONCURRENCY_RISK" | "TEMPORARY_HACK" | "POOR_OBSERVABILITY" | "OTHER",
      "severity": 0 | 1 | 2 | 3,
      "title": "short title",
      "explanation": "short explanation (max 2 sentences)",
      "suggestedFix": "optional concrete suggestion (max 2 sentences)"
    }
  ]
}

Severity levels:
- 0 = no issue
- 1 = low (minor concern, nice to fix)
- 2 = medium (should fix before production)
- 3 = high (critical, must fix before production)

Rules:
- If there are no meaningful issues, return overallSeverity: 0 and issues: []
- Keep explanations and fixes concise (max 2 sentences each)
- Do NOT include any text outside the JSON object
- Focus on production-readiness concerns, not style or minor refactoring`;
}

// ============================================================================
// Main Analysis Function
// ============================================================================

/**
 * Analyze a code snippet using the LLM.
 *
 * @param params - Analysis parameters
 * @returns LlmAnalysisResult or null if LLM is unavailable/fails
 */
export async function analyzeSnippetWithLlm(params: {
  file: string;
  language?: string;
  snippet: string;
  diffContext?: string;
  modelName?: string;
}): Promise<LlmAnalysisResult | null> {
  // Check if API key is configured
  if (!config.GROQ_API_KEY) {
    console.warn("[LLM] GROQ_API_KEY not configured, skipping LLM analysis");
    return null;
  }

  const openai = createOpenAIClient();
  if (!openai) {
    console.warn("[LLM] Failed to create OpenAI client");
    return null;
  }

  const model = params.modelName || "llama-3.1-8b-instant";
  const prompt = buildVibePrompt(params);

  try {
    const completion = await openai.chat.completions.create({
      model,
      messages: [{ role: "user", content: prompt }],
      temperature: 0.1,
      max_tokens: 512,
    });

    const content = completion.choices[0]?.message?.content;
    if (!content) {
      console.warn("[LLM] Empty response from model");
      return {
        overallSeverity: 0,
        issues: [],
      };
    }

    // Parse JSON response
    let parsed: unknown;
    try {
      // Try to extract JSON from the response (in case there's extra text)
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      const jsonStr = jsonMatch ? jsonMatch[0] : content;
      parsed = JSON.parse(jsonStr);
    } catch (parseError) {
      console.error("[LLM] Failed to parse JSON response:", parseError);
      console.error("[LLM] Raw response:", content);
      return {
        overallSeverity: 0,
        issues: [],
      };
    }

    // Validate and normalize the response
    return validateAndNormalize(parsed);
  } catch (error) {
    console.error("[LLM] API call failed:", error);
    return null;
  }
}

/**
 * Validate and normalize the parsed LLM response.
 */
function validateAndNormalize(parsed: unknown): LlmAnalysisResult {
  const defaultResult: LlmAnalysisResult = {
    overallSeverity: 0,
    issues: [],
  };

  if (!parsed || typeof parsed !== "object") {
    console.warn("[LLM] Invalid response structure");
    return defaultResult;
  }

  const obj = parsed as Record<string, unknown>;

  // Validate overallSeverity
  let overallSeverity: LlmSeverity = 0;
  if (typeof obj.overallSeverity === "number" && [0, 1, 2, 3].includes(obj.overallSeverity)) {
    overallSeverity = obj.overallSeverity as LlmSeverity;
  }

  // Validate issues array
  const issues: LlmIssue[] = [];
  if (Array.isArray(obj.issues)) {
    for (const item of obj.issues) {
      if (item && typeof item === "object") {
        const issue = item as Record<string, unknown>;
        const validKinds: LlmIssueKind[] = [
          "MISSING_ERROR_HANDLING",
          "HIDDEN_ASSUMPTIONS",
          "SCALING_RISK",
          "CONCURRENCY_RISK",
          "TEMPORARY_HACK",
          "POOR_OBSERVABILITY",
          "OTHER",
        ];

        const kind = validKinds.includes(issue.kind as LlmIssueKind)
          ? (issue.kind as LlmIssueKind)
          : "OTHER";

        const severity =
          typeof issue.severity === "number" && [0, 1, 2, 3].includes(issue.severity)
            ? (issue.severity as LlmSeverity)
            : 1;

        const title = typeof issue.title === "string" ? issue.title : "Unknown issue";
        const explanation =
          typeof issue.explanation === "string" ? issue.explanation : "No explanation provided";
        const suggestedFix =
          typeof issue.suggestedFix === "string" ? issue.suggestedFix : undefined;

        issues.push({
          kind,
          severity,
          title,
          explanation,
          suggestedFix,
        });
      }
    }
  }

  return {
    overallSeverity,
    issues,
  };
}
